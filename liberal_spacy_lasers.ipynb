{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "challenging-prairie",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "empty-lecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "# nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "import spacy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "complete-retreat",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open('data/pickle_jar/cleaned.pkl', 'rb')\n",
    "tweets = pickle.load(pickle_in)\n",
    "pickle_in.close()\n",
    "\n",
    "tweets.reset_index(inplace=True)\n",
    "tweets.drop(columns = 'index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "shared-madrid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1970258 entries, 0 to 1970257\n",
      "Data columns (total 21 columns):\n",
      " #   Column                   Dtype         \n",
      "---  ------                   -----         \n",
      " 0   created_at               datetime64[ns]\n",
      " 1   id                       int64         \n",
      " 2   full_text                object        \n",
      " 3   truncated                bool          \n",
      " 4   in_reply_to_screen_name  object        \n",
      " 5   is_quote_status          bool          \n",
      " 6   retweet_count            int64         \n",
      " 7   favorite_count           int64         \n",
      " 8   lang                     object        \n",
      " 9   retweeted_status         object        \n",
      " 10  names                    object        \n",
      " 11  screen_names             object        \n",
      " 12  locations                object        \n",
      " 13  follower_counts          int64         \n",
      " 14  user_created_at          object        \n",
      " 15  verified                 bool          \n",
      " 16  statuses_counts          int64         \n",
      " 17  location                 object        \n",
      " 18  country                  object        \n",
      " 19  hashtags                 object        \n",
      " 20  withheld_in_countries    object        \n",
      "dtypes: bool(3), datetime64[ns](1), int64(5), object(12)\n",
      "memory usage: 276.2+ MB\n"
     ]
    }
   ],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "approximate-cleanup",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1970258, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "interpreted-mitchell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "created_at                       0\n",
       "id                               0\n",
       "full_text                        0\n",
       "truncated                        0\n",
       "in_reply_to_screen_name    1525932\n",
       "is_quote_status                  0\n",
       "retweet_count                    0\n",
       "favorite_count                   0\n",
       "lang                             0\n",
       "retweeted_status           1970258\n",
       "names                            0\n",
       "screen_names                     0\n",
       "locations                        0\n",
       "follower_counts                  0\n",
       "user_created_at                  0\n",
       "verified                         0\n",
       "statuses_counts                  0\n",
       "location                   1889581\n",
       "country                    1889581\n",
       "hashtags                   1234431\n",
       "withheld_in_countries      1970213\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "silver-analysis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.095% of the dataset has location data\n"
     ]
    }
   ],
   "source": [
    "location_perc = 100 * tweets.dropna(subset =['location']).shape[0] / tweets.shape[0]\n",
    "print(f'{round(location_perc, 3)}% of the dataset has location data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "rubber-departure",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tweets.dropna(subset=['hashtags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "celtic-diploma",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags_all = []\n",
    "for row in df['hashtags']:\n",
    "    for item in row:\n",
    "        hashtags_all.append(item.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "victorian-tourist",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "climatechange                403207\n",
       "globalwarming                 55929\n",
       "climateaction                 50345\n",
       "environment                   48337\n",
       "climate                       38087\n",
       "                              ...  \n",
       "notshower                         1\n",
       "lasallianswithoutlimits           1\n",
       "floodfutures                      1\n",
       "republicanskillanimals            1\n",
       "internationalpolarbearday         1\n",
       "Length: 166071, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(hashtags_all).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "relevant-vienna",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_hashtags = list(pd.Series(hashtags_all).value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "southeast-closure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['climatechange',\n",
       " 'globalwarming',\n",
       " 'climateaction',\n",
       " 'environment',\n",
       " 'climate',\n",
       " 'actonclimate',\n",
       " 'energy',\n",
       " 'climatechangeisreal',\n",
       " 'auspol',\n",
       " 'sustainability']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_hashtags[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "egyptian-visitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "denier_tags = ['climatechangeisfalse', 'climatechangenotreal', 'climatechangehoax', \n",
    "               'globalwarminghoax', 'tcot', 'ccot', 'tlot', 'pjnet', 'rednationrising', 'votered', \n",
    "               'libtard', 'libtards', 'maga']\n",
    "\n",
    "believer_tags = ['climatechangeisreal', 'actonclimate', 'extinctionrebellion', 'climateemergency', \n",
    "                  'climateactionnow', 'capitalism', 'public_health', 'climateaction', 'humanityextinction',\n",
    "                'activism', 'noplanetb', 'savetheplanet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ultimate-vitamin",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "believer = []\n",
    "denier = []\n",
    "unsure = []\n",
    "believe_series = []\n",
    "count = 0\n",
    "for idx, row in df['hashtags'].iteritems():\n",
    "    believe = 0\n",
    "    deny = 0 \n",
    "    for tag in row:\n",
    "        if tag.lower() in denier_tags:\n",
    "            deny += 1\n",
    "        elif tag.lower() in believer_tags:\n",
    "            believe += 1\n",
    "    if (believe > 0) and (deny == 0):\n",
    "        believer.append(int(idx))\n",
    "        believe_series.append(1)\n",
    "    elif (believe == 0) and (deny > 0):\n",
    "        denier.append(int(idx))\n",
    "        believe_series.append(0)\n",
    "    else:\n",
    "        unsure.append(int(idx))\n",
    "        believe_series.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "respective-prague",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(believer = believe_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "demographic-record",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_train = df.dropna(subset=['believer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "legendary-jamaica",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                               14027\n",
       "Globally l Planet Earth        11973\n",
       "Tampere, Finland                9519\n",
       "Right Here......                3128\n",
       "United States                   2721\n",
       "                               ...  \n",
       "SF | LA | SAC | SD | SB            1\n",
       "Hudson Valley + LI Sound           1\n",
       "Towson, Maryland                   1\n",
       "Sicilia                            1\n",
       "Dallas, TX - Southeast Asia        1\n",
       "Name: locations, Length: 9663, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_train['locations'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "painted-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_clean(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r'[@#][\\w]+','', tweet)\n",
    "#     tweet = re.sub(r'[#]','', tweet)\n",
    "    tweet = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', tweet)\n",
    "    tweet = re.sub(r'\\s{2,5}', ' ', tweet)\n",
    "    tweet = re.sub(r'\\n', ' ', tweet)\n",
    "\n",
    "    return tweet.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "documented-genesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_to_vec(tweet):\n",
    "    tweet = re_clean(tweet)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "incorporated-korea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i'd even take mushy peas over baked brits.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"@StephenLeahy I'd even take mushy peas over baked Brits.\\n#ActOnClimate\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = -3\n",
    "\n",
    "print(re_clean(to_train.iloc[n]['full_text']))\n",
    "\n",
    "to_train.iloc[n]['full_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fitted-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tweets = to_train['full_text'].apply(lambda x: re_clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "upset-brick",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_train['believer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "arabic-football",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('english') + list(string.punctuation) + denier_tags + believer_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "hairy-church",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweets(tweet):\n",
    "    tok = nltk.regexp_tokenize(tweet, r\"([a-zA-Z]+(?:'[a-z]+)?)\")\n",
    "    return [word.lower() for word in tok if word.lower() not in stopwords_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "liberal-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_data = list(map(process_tweets, cleaned_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "improving-joshua",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seems', 'really', 'need']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_data[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "paperback-professor",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "processed_data = [[lemmatizer.lemmatize(token) for token in tweet] for tweet in token_data]\n",
    "\n",
    "# Prints \"This sentence wa transformed using WordNet Lemmatizer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "mediterranean-capacity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thomas', 'dolby', 'blinded', 'science']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data[739]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "potential-pharmaceutical",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vocab = set()\n",
    "for tweet_token in processed_data:\n",
    "    all_vocab.update(tweet_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "structural-percentage",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_concat = []\n",
    "for tweet in processed_data:\n",
    "    tweets_concat += tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "architectural-difference",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_freqdist = FreqDist(tweets_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scenic-torture",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ultimate-horse",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cleaned_tweets, y, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "infinite-fountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tf_idf_data_train = vectorizer.fit_transform(X_train)\n",
    "tf_idf_data_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-testimony",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "potential-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "surprising-gossip",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier.fit(tf_idf_data_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "alternative-dallas",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = rf_classifier.predict(tf_idf_data_train)\n",
    "y_pred_test = rf_classifier.predict(tf_idf_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "incorporated-gibson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9429774205893608"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "relative-coupon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  286,  1616],\n",
       "       [   23, 26818]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-firmware",
   "metadata": {},
   "source": [
    "## Apply Classifier to remainder dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "talented-chester",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'remember the clean power plan? well trump wants to reverse course because he believes that is a hoax.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-carbon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-carol",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-appearance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ds01] *",
   "language": "python",
   "name": "conda-env-ds01-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
